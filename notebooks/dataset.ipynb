{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet6 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio as rio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import re\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from shapely.geometry import Polygon\n",
    "from imantics import Polygons, Mask\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, what I need?\n",
    "# Class discription -> kinda done!\n",
    "# init -> done\n",
    "# getitem -> done\n",
    "# poly to mask -> completed\n",
    "# mask to polygan -> How can I extract polygons given the mask?\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# Complete these steps for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shimash\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vec2raster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec_dir = \"data/train/AOI_11_Rotterdam/geojson_buildings/\"\n",
    "input_img_dir = \"data/train/AOI_11_Rotterdam/PS-RGB/\"\n",
    "#input_sar_dir = \"data/train/AOI_11_Rotterdam/SAR-Intensity/\"\n",
    "output_dir = \"data/train/AOI_11_Rotterdam/gt_masks/\"\n",
    "\n",
    "for fi in os.listdir(input_vec_dir):\n",
    "    \n",
    "    if fi.endswith(\".geojson\"):\n",
    "        input_vec_file = os.path.join(input_vec_dir,fi)\n",
    "        input_img_file = os.path.join(input_img_dir,fi.replace('_Buildings_', '_PS-RGB_').replace('.geojson', '.tif'))\n",
    "        output_file = os.path.join(output_dir,fi.replace('_Buildings_', '_PS-RGB_').replace('.geojson', '.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sn6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SpaceNet6 Dataset.\"\"\"\n",
    "\n",
    "class SpaceNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_fp,\n",
    "        image_dir,\n",
    "        sar_dir,\n",
    "        #         test_dir,\n",
    "        transform=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Path to RGB images directory.\n",
    "            sar_dir (string): ...\n",
    "            mask_dir (string): ... \n",
    "            tile_number (string): ...\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.csv_fp = csv_fp\n",
    "        self.data = pd.read_csv(csv_fp)\n",
    "        self.image_dir = image_dir\n",
    "        self.sar_dir = sar_dir\n",
    "        self.mask_list = self.create_poly_list()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.tile_id_list = self._get_tile_id_list()\n",
    "\n",
    "    #         self.test_dir = test_dir\n",
    "    #         self.test_id_list = self.test_id_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_id_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rgb = self.get_rgb(idx)\n",
    "        mask = self.get_mask(idx)\n",
    "        sar = self.get_sar(idx)\n",
    "        edge = self.get_edge(idx, mask)\n",
    "\n",
    "        segmaps = [mask, edge]\n",
    "\n",
    "        if self.transform:\n",
    "            sar, segmaps = self.transform(sar, segmaps)\n",
    "#         img = torch.from_numpy(sar).float()\n",
    "#         canny = self.calc_canny(img)\n",
    "\n",
    "        return sar, segmaps\n",
    "\n",
    "    def get_sar(self, idx):\n",
    "        create_SAR_path = os.path.join(\n",
    "            self.sar_dir,\n",
    "            f\"SN6_Train_AOI_11_Rotterdam_SAR-Intensity_{self.tile_id_list[idx][0]}.tif\",\n",
    "        )\n",
    "        with rio.open(create_SAR_path) as lidar_dem:\n",
    "            img = np.zeros((900, 900, 4))\n",
    "            img[:, :, 0] = lidar_dem.read(1)\n",
    "            img[:, :, 1] = lidar_dem.read(2)\n",
    "            img[:, :, 2] = lidar_dem.read(3)\n",
    "            img[:, :, 3] = lidar_dem.read(4)\n",
    "        img = img * 255 / np.max(img)\n",
    "        return img\n",
    "\n",
    "    def get_rgb(self, idx):\n",
    "        create_RGB_path = os.path.join(\n",
    "            self.image_dir,\n",
    "            f\"SN6_Train_AOI_11_Rotterdam_PS-RGB_{self.tile_id_list[idx][0]}.tif\",\n",
    "        )\n",
    "        with rio.open(create_RGB_path) as lidar_dem:\n",
    "            img = np.zeros((900, 900, 3))\n",
    "            img[:, :, 0] = lidar_dem.read(1)\n",
    "            img[:, :, 1] = lidar_dem.read(2)\n",
    "            img[:, :, 2] = lidar_dem.read(3)\n",
    "        return img\n",
    "\n",
    "    def get_mask(self, idx):\n",
    "        return self.generate_mask(\n",
    "            self.mask_list[idx][1], self.mask_list[idx][2]\n",
    "        )\n",
    "\n",
    "    def generate_mask(self, start, end):\n",
    "        mask_img = Image.new(\"1\", (900, 900), 0)\n",
    "        poly = ImageDraw.Draw(mask_img)\n",
    "        for i in range(start, end + 1):\n",
    "            row = self.data.loc[i, \"PolygonWKT_Pix\"]\n",
    "            expression = re.findall(\n",
    "                \"[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?\\d+)?\", row\n",
    "            )\n",
    "            tup = (float(expression[0]), float(expression[1]))\n",
    "            for i in range(2, len(expression), 2):\n",
    "                temp = (float(expression[i]), float(expression[i + 1]))\n",
    "                tup = tup + temp\n",
    "            poly.polygon(tup, outline=1, fill=1)\n",
    "        mask = np.array(mask_img).astype(float)\n",
    "        return mask\n",
    "\n",
    "    def onehot_to_binary_edges(self, mask, radius):\n",
    "        if radius < 0:\n",
    "            return mask\n",
    "        mask = mask.astype(np.uint8)\n",
    "        # We need to pad the borders for boundary conditions\n",
    "        mask_pad = np.pad(\n",
    "            mask, ((1, 1), (1, 1)), mode=\"constant\", constant_values=0\n",
    "        )\n",
    "        edgemap = np.zeros(mask.shape)\n",
    "        dist = distance_transform_edt(mask_pad)\n",
    "        dist = dist[1:-1, 1:-1]\n",
    "        dist[dist > radius] = 0\n",
    "        edgemap += dist\n",
    "        #         edgemap = np.expand_dims(edgemap, axis=0)\n",
    "        #         edgemap = (edgemap > 0).astype(np.uint8)\n",
    "        return edgemap\n",
    "\n",
    "    def get_edge(self, idx, mask):\n",
    "        _edgemap = mask\n",
    "        _edgemap = self.onehot_to_binary_edges(_edgemap, 1)\n",
    "        return _edgemap\n",
    "\n",
    "    def create_poly_list(self):\n",
    "        pointer = 0\n",
    "        poly_index_list = []\n",
    "        while pointer < len(self.data):\n",
    "            start = pointer\n",
    "            end = pointer\n",
    "            tile_number_st = self.data[\"ImageId\"][pointer].rfind(\"_\")\n",
    "            tile_number = self.data[\"ImageId\"][pointer][tile_number_st + 1 :]\n",
    "            while (pointer + 2) < len(self.data) and (\n",
    "                self.data[\"TileBuildingId\"][pointer]\n",
    "                < self.data[\"TileBuildingId\"][pointer + 1]\n",
    "            ):\n",
    "                end += 1\n",
    "                pointer += 1\n",
    "            poly_index_list.append(\n",
    "                [tile_number, start, end, self.data[\"ImageId\"][pointer]]\n",
    "            )\n",
    "            pointer += 1\n",
    "        return poly_index_list\n",
    "\n",
    "    def random_rotation(self, image, mask, sar):\n",
    "        orient = np.random.randint(0, 4)\n",
    "        image = np.rot90(image, orient)\n",
    "        mask = np.rot90(mask, orient)\n",
    "        sar = np.rot90(sar, orient)\n",
    "        return image, mask, sar, orient\n",
    "\n",
    "    def _get_tile_id_list(self):\n",
    "        tile_list = []\n",
    "        csv_list = self.create_poly_list()\n",
    "        for tile in range(len(csv_list)):\n",
    "            tile_list.append([csv_list[tile][3], csv_list[tile][0]])\n",
    "        return tile_list\n",
    "\n",
    "    def create_output_csv(self):\n",
    "        with open(\"solution.csv\", \"w\") as csv_file:\n",
    "            fieldnames = [\"ImageId\", \"PolygonWKT_Pix\", \"Confidence\"]\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "    def csv_add_newline(self, image_id, polygons, score):\n",
    "        with open(\"solution.csv\", \"a\", newline=\"\") as csv_file:\n",
    "            fieldnames = [\"ImageId\", \"PolygonWKT_Pix\", \"Confidence\"]\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"ImageId\": image_id,\n",
    "                    \"PolygonWKT_Pix\": polygons,\n",
    "                    \"Confidence\": score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def create_polygon(self, idx, mask):\n",
    "        mask = mask.numpy()\n",
    "        binary_mask = mask.astype(np.uint8)\n",
    "        contours, hierarchy = cv2.findContours(\n",
    "            binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        for i in range(len(contours)):\n",
    "            points = []\n",
    "            contour = np.squeeze(contours[i])\n",
    "            for j in range(len(contour)):\n",
    "                points.append((contour[j][0], contour[j][1]))\n",
    "            if contour.shape[0] >= 3:\n",
    "                polygon = Polygon(points)\n",
    "            # add a newline to csv!\n",
    "            image_id = self.mask_list[idx][3]\n",
    "            self.csv_add_newline(image_id, polygon.wkt, 1.0)\n",
    "            # print(polygon.wkt)\n",
    "    \n",
    "    def calc_canny(self, inputs):\n",
    "        im_arr = inputs.cpu().numpy().transpose((0,2,3,1)).astype(np.uint8)\n",
    "        canny = np.zeros((x_size[0], 1, x_size[2], x_size[3]))\n",
    "        for i in range(x_size[0]):\n",
    "            canny[i] = cv2.Canny(im_arr[i],10,100)\n",
    "        canny = torch.from_numpy(canny).float()\n",
    "        return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dir = \"data/train/AOI_11_Rotterdam/geojson_buildings/\"\n",
    "img_dir = \"data/train/AOI_11_Rotterdam/PS-RGB/\"\n",
    "sar_dir = \"data/train/AOI_11_Rotterdam/SAR-Intensity/\"\n",
    "out_dir = \"data/train/AOI_11_Rotterdam/gt_masks/\"\n",
    "csv_dir = \"data/train/AOI_11_Rotterdam/SummaryData/SN6_Train_AOI_11_Rotterdam_Buildings.csv\"\n",
    "\n",
    "test_space = SpaceNetDataset(csv_fp=csv_dir, image_dir=img_dir, sar_dir=sar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_space.get_sar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_space.get_rgb(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = test_space.get_mask(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_space.create_polygon(0, mask)\n",
    "# polygons = Mask(mask).polygons()\n",
    "\n",
    "# print(polygons.points)\n",
    "#print(polygons.segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar, mask =  test_space[0]\n",
    "sar_1, mask_1 = test_space[1]\n",
    "# sar = torch.from_numpy(sar).float()\n",
    "# sar_1 = torch.from_numpy(sar_1).float()\n",
    "# sar = sar.unsqueeze(0).view((1,4,900,900))\n",
    "# sar_1 = sar_1.unsqueeze(0).view((1,4,900,900))\n",
    "# inputs = torch.cat((sar, sar_1),0)\n",
    "# x_size = inputs.size() \n",
    "# x_size[0] = 2\n",
    "# print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_canny(inputs):\n",
    "    im_arr = np.uint8(inputs)\n",
    "    return cv2.Canny(im_arr,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900)\n"
     ]
    }
   ],
   "source": [
    "canny = calc_canny(sar)\n",
    "print(canny.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402\n"
     ]
    }
   ],
   "source": [
    "test_space.test_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = (mask*mask).sum(1).sum(0)\n",
    "union = (mask+mask).sum(1).sum(0)\n",
    "iou = (intersect+0.001)/(union-intersect+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = mask*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([900, 900])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_canny(self,inputs):\n",
    "    x_size = inputs.size()\n",
    "    # print(x_size)\n",
    "    im_arr = inputs.cpu().numpy().transpose((0,2,3,1)).astype(np.uint8)\n",
    "    # print(im_arr[0].shape)\n",
    "    canny = np.zeros((x_size[0], 1,  x_size[2], x_size[3]))\n",
    "    # print(canny.shape)\n",
    "    for i in range(x_size[0]):\n",
    "        canny[i] = cv2.Canny(im_arr[0],10,100)\n",
    "    canny = torch.from_numpy(canny).float()\n",
    "    return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
