{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet6 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio as rio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import re\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from shapely.geometry import Polygon\n",
    "from imantics import Polygons, Mask\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, what I need?\n",
    "# Class discription -> kinda done!\n",
    "# init -> done\n",
    "# getitem -> done\n",
    "# poly to mask -> completed\n",
    "# mask to polygan -> How can I extract polygons given the mask?\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# Complete these steps for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vec2raster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec_dir = \"data/train/AOI_11_Rotterdam/geojson_buildings/\"\n",
    "input_img_dir = \"data/train/AOI_11_Rotterdam/PS-RGB/\"\n",
    "#input_sar_dir = \"data/train/AOI_11_Rotterdam/SAR-Intensity/\"\n",
    "output_dir = \"data/train/AOI_11_Rotterdam/gt_masks/\"\n",
    "\n",
    "for fi in os.listdir(input_vec_dir):\n",
    "    \n",
    "    if fi.endswith(\".geojson\"):\n",
    "        input_vec_file = os.path.join(input_vec_dir,fi)\n",
    "        input_img_file = os.path.join(input_img_dir,fi.replace('_Buildings_', '_PS-RGB_').replace('.geojson', '.tif'))\n",
    "        output_file = os.path.join(output_dir,fi.replace('_Buildings_', '_PS-RGB_').replace('.geojson', '.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sn6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SpaceNet6 Dataset.\"\"\"\n",
    "\n",
    "class SpaceNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_dir,\n",
    "        image_dir,\n",
    "        sar_dir,\n",
    "#         test_dir,\n",
    "        transform=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Path to RGB images directory.\n",
    "            sar_dir (string): ...\n",
    "            mask_dir (string): ... \n",
    "            tile_number (string): ...\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.csv_dir = csv_dir\n",
    "        self.data = pd.read_csv(csv_dir)\n",
    "        self.image_dir = image_dir\n",
    "        self.sar_dir = sar_dir\n",
    "        self.mask_list = self.create_poly_list()\n",
    "        self.transform = transform\n",
    "        self.tile_id_list = self.tile_id_list()\n",
    "#         self.test_dir = test_dir\n",
    "#         self.test_id_list = self.test_id_list()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tile_id_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        image = self.get_rgb(idx)\n",
    "        mask = self.get_mask(idx)\n",
    "        sar = self.get_sar(idx)\n",
    "        edge = self.get_edge(idx, mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            image, mask, _ = self.transform(image, mask)\n",
    "\n",
    "        return sar, mask, image, edge \n",
    "    \n",
    "    def get_sar(self, idx):\n",
    "        create_SAR_path = self.sar_dir +\"SN6_Train_AOI_11_Rotterdam_SAR-Intensity_\" + self.tile_id_list[idx][0] + \".tif\"\n",
    "        with rio.open(create_SAR_path) as lidar_dem:\n",
    "            img = np.zeros((900,900,4))\n",
    "            img[:,:,0] = lidar_dem.read(1)\n",
    "            img[:,:,1] = lidar_dem.read(2)\n",
    "            img[:,:,2] = lidar_dem.read(3)\n",
    "            img[:,:,3] = lidar_dem.read(4)\n",
    "        return torch.from_numpy(img*255/np.max(img))\n",
    "    \n",
    "    def get_rgb(self, idx):\n",
    "        create_RGB_path = self.image_dir +\"SN6_Train_AOI_11_Rotterdam_PS-RGB_\" + self.tile_id_list[idx][0] + \".tif\"\n",
    "        with rio.open(create_RGB_path) as lidar_dem:\n",
    "            img = np.zeros((900,900,3))\n",
    "            img[:,:,0] = lidar_dem.read(1)\n",
    "            img[:,:,1] = lidar_dem.read(2)\n",
    "            img[:,:,2] = lidar_dem.read(3)\n",
    "        return torch.from_numpy(img)\n",
    "\n",
    "    def get_mask(self, idx):\n",
    "        return self.generate_mask(self.mask_list[idx][1], self.mask_list[idx][2])\n",
    "         \n",
    "    def generate_mask(self, start, end):\n",
    "        mask_img = Image.new('1', (900, 900), 0)\n",
    "        poly = ImageDraw.Draw(mask_img)\n",
    "        for i in range(start,end+1):\n",
    "            row = self.data.loc[i,'PolygonWKT_Pix']\n",
    "            expression = re.findall(\"[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?\\d+)?\", row)\n",
    "            tup = (float(expression[0]), float(expression[1]))\n",
    "            for i in range(2,len(expression),2):\n",
    "                temp = (float(expression[i]),float(expression[i+1]))\n",
    "                tup = tup + temp\n",
    "            poly.polygon(tup, outline = 1, fill = 1)\n",
    "        mask = np.array(mask_img)\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        return mask \n",
    "    \n",
    "    def onehot_to_binary_edges(self, mask, radius):\n",
    "        mask = mask.numpy()\n",
    "        if radius < 0:\n",
    "            return mask\n",
    "        mask = mask.astype(np.uint8)\n",
    "        # We need to pad the borders for boundary conditions\n",
    "        mask_pad = np.pad(mask, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n",
    "        edgemap = np.zeros(mask.shape)\n",
    "        dist = distance_transform_edt(mask_pad)\n",
    "        #print(dist)\n",
    "        dist = dist[1:-1, 1:-1]\n",
    "        dist[dist > radius] = 0\n",
    "        edgemap += dist\n",
    "#         edgemap = np.expand_dims(edgemap, axis=0)    \n",
    "#         edgemap = (edgemap > 0).astype(np.uint8)\n",
    "        return edgemap\n",
    "    \n",
    "    def get_edge(self, idx, mask):\n",
    "        _edgemap = mask\n",
    "        _edgemap = self.onehot_to_binary_edges(_edgemap, 1)\n",
    "        edgemap = torch.from_numpy(_edgemap).float()\n",
    "        return edgemap\n",
    "    \n",
    "    def create_poly_list(self):\n",
    "        pointer = 0\n",
    "        poly_index_list = []\n",
    "        while pointer < len(self.data):\n",
    "            start = pointer\n",
    "            end = pointer\n",
    "            tile_number_st = self.data['ImageId'][pointer].rfind('_')\n",
    "            tile_number = self.data['ImageId'][pointer][tile_number_st+1:]\n",
    "            while (pointer+2) < len(self.data) and (self.data['TileBuildingId'][pointer] < self.data['TileBuildingId'][pointer+1]):\n",
    "                end +=1\n",
    "                pointer +=1\n",
    "            poly_index_list.append([tile_number, start, end, self.data['ImageId'][pointer]])\n",
    "            pointer +=1\n",
    "        return poly_index_list\n",
    "        \n",
    "    def random_rotation(self, image, mask):\n",
    "        orient = np.random.randint(0, 4)\n",
    "        image = np.rot90(image, orient)\n",
    "        mask = np.rot90(mask, orient)\n",
    "        sar = np.rot90(sar, orient)\n",
    "        return image, mask, sar, orient\n",
    "\n",
    "    def tile_id_list(self):\n",
    "        tile_list = []\n",
    "        csv_list = self.create_poly_list()\n",
    "        for tile in range(len(csv_list)):\n",
    "            tile_list.append([csv_list[tile][3], csv_list[tile][0]])\n",
    "        return tile_list\n",
    "    \n",
    "    def create_output_csv(self):\n",
    "        with open('solution.csv', 'w') as csv_file:\n",
    "            fieldnames = ['ImageId','PolygonWKT_Pix','Confidence']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "    \n",
    "    def csv_add_newline(self, image_id, polygons, score):\n",
    "        with open('solution.csv', 'a', newline='') as csv_file:\n",
    "            fieldnames = ['ImageId','PolygonWKT_Pix','Confidence']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writerow({'ImageId': image_id, 'PolygonWKT_Pix': polygons, 'Confidence': score})\n",
    "    \n",
    "    def create_polygon(self, idx, mask):\n",
    "        mask = mask.numpy()\n",
    "        binary_mask = mask.astype(np.uint8)\n",
    "        contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in range (len(contours)):\n",
    "            points = []\n",
    "            contour = np.squeeze(contours[i])\n",
    "            for j in range(len(contour)):\n",
    "                points.append((contour[j][0], contour[j][1]))\n",
    "            if contour.shape[0] >= 3:\n",
    "                polygon = Polygon(points)   \n",
    "            #add a newline to csv!   \n",
    "            image_id = self.mask_list[idx][3]\n",
    "            self.csv_add_newline(image_id, polygon.wkt, 1.0)\n",
    "            #print(polygon.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dir = \"data/train/AOI_11_Rotterdam/geojson_buildings/\"\n",
    "img_dir = \"data/train/AOI_11_Rotterdam/PS-RGB/\"\n",
    "sar_dir = \"data/train/AOI_11_Rotterdam/SAR-Intensity/\"\n",
    "out_dir = \"data/train/AOI_11_Rotterdam/gt_masks/\"\n",
    "csv_dir = \"data/train/AOI_11_Rotterdam/SummaryData/SN6_Train_AOI_11_Rotterdam_Buildings.csv\"\n",
    "\n",
    "test_space = SpaceNetDataset(csv_dir=csv_dir, image_dir=img_dir, sar_dir=sar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_space.get_sar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_space.get_rgb(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = test_space.get_mask(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_space.create_polygon(0, mask)\n",
    "# polygons = Mask(mask).polygons()\n",
    "\n",
    "# print(polygons.points)\n",
    "#print(polygons.segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar, mask, rgb, edge =  test_space[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
